{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacek/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import ta\n",
    "\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.contrib.factories import InstrumentsCandlesFactory\n",
    "import oandapyV20.endpoints.forexlabs as labs\n",
    "# https://media.readthedocs.org/pdf/oanda-api-v20/latest/oanda-api-v20.pdf\n",
    "# https://financetrain.com/best-python-librariespackages-finance-financial-data-scientists/\n",
    "# https://github.com/mrjbq7/ta-lib\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_loss = 0.0030\n",
    "take_profit = 0.0070\n",
    "periods = 5\n",
    "commision = 0.0002\n",
    "number_of_models_to_test = 10\n",
    "days_to_train = 5\n",
    "granularity_param = 'H1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = API(access_token='7f736aabc877f3ea75bc844c79814d7c-998e41725285ea6d54b836e8b93fe4f6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist(api, instrument, start_days, end_days, granularity):\n",
    "\n",
    "    start_date = (dt.datetime.now()-dt.timedelta(days=start_days)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_date = (dt.datetime.now()-dt.timedelta(days=end_days, hours=2,minutes=4)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    params ={\n",
    "                \"from\": start_date,\n",
    "                \"to\": end_date,\n",
    "                \"granularity\":granularity,\n",
    "            }\n",
    "\n",
    "    df_list = []\n",
    "    for r in InstrumentsCandlesFactory(instrument=instrument,params=params):\n",
    "        api.request(r)\n",
    "        df = pd.DataFrame(r.response['candles'])\n",
    "        if(df.empty==False):\n",
    "            time = df['time']\n",
    "            volume = pd.DataFrame(df['volume'].apply(pd.Series))\n",
    "            df = pd.DataFrame(df['mid'].apply(pd.Series))\n",
    "            df = pd.concat([df,time,volume], axis=1)\n",
    "            df['time'] = pd.to_datetime(df['time'], format='%Y-%m-%dT%H:%M:%S.000000000Z')\n",
    "            #df.set_index('time',inplace=True)\n",
    "            df_list.append(df)\n",
    "    \n",
    "    final = pd.concat(df_list)\n",
    "    \n",
    "    names = {\n",
    "        'o': 'open',\n",
    "        'c': 'close',\n",
    "        'h': 'high',\n",
    "        'l': 'low',\n",
    "        0: 'vol',\n",
    "        'time': 'time',\n",
    "    }\n",
    "    new_names = []\n",
    "    for column_name in final.columns:\n",
    "        new_names.append(names[column_name])\n",
    "    final.columns = new_names\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal(client, instrument, perdiod):\n",
    "\n",
    "    \n",
    "    \n",
    "    params = {\n",
    "        \"instrument\": instrument,\n",
    "        \"period\": perdiod\n",
    "    }\n",
    "    \n",
    "    # PERIOD VALUES\n",
    "    #3600 - 1 hour\n",
    "    #43200 - 12 hours\n",
    "    #86400 - 1 day\n",
    "    #604800 - 1 week\n",
    "    #2592000 - 1 month\n",
    "    #7776000 - 3 months\n",
    "    #15552000 - 6 months\n",
    "    #31536000 - 1 year\n",
    "    # http://developer.oanda.com/rest-live/forex-labs/\n",
    "\n",
    "    r = labs.Calendar(params=params)\n",
    "    client.request(r)\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(r.response, orient='columns')\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']*1000000000)\n",
    "    df = df[['impact', 'timestamp']]\n",
    "    df.columns = ['impact', 'time']\n",
    "\n",
    "    return df.groupby('time').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(history, calendar):\n",
    "    return pd.merge(history, calendar, left_on = 'time', right_on = 'time', how='outer')\\\n",
    "                                                                            .set_index('time')\\\n",
    "                                                                            .astype(float)\\\n",
    "                                                                            .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ta(df, period):\n",
    "    df = ta.add_all_ta_features(df, \"open\", \"high\", \"low\", \"close\", \"vol\", fillna=False)\n",
    "    \n",
    "    features_list = []\n",
    "    for i in range(period):\n",
    "        for feature in df.drop([\"open\", \"high\", \"low\", \"close\", \"vol\", \"impact\"], axis=1).columns.tolist():\n",
    "            df[feature+\"_change_\"+str(i+1)] = (df[feature] - df[feature].shift(1+i)) / df[feature].shift(1+i)\n",
    "            if i == 0:\n",
    "                features_list.append(feature)\n",
    "            \n",
    "    for feature in features_list:\n",
    "        df = df.drop(feature, axis=1)\n",
    "        \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\\\n",
    "            .dropna(axis=1, thresh=len(df) - 50)\\\n",
    "            .iloc[100:]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broaden_impact(df, period):\n",
    "    df = df.reset_index().sort_values('time').set_index('time')\n",
    "\n",
    "    for i in range(periods):\n",
    "        df.loc[\n",
    "            (df['impact'].shift(-1-i) != 0)\n",
    "        ,'impact'] = df['impact'].shift(-1-i)\n",
    "    \n",
    "    df['impact'] = df['impact'].fillna(0)\n",
    "\n",
    "    return df[df['low'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sessions(df):\n",
    "    df.loc[df.index.hour.isin([7,8,9,10,11,12,13,14,15,16]), 'eu_session'] = 1\n",
    "    df.loc[df['eu_session'] != 1, 'eu_session'] = 0\n",
    "\n",
    "    df.loc[df.index.hour.isin([21,22,23,24,1,2,3,4,5,6,7]), 'asia_session'] = 1\n",
    "    df.loc[df['asia_session'] != 1, 'asia_session'] = 0\n",
    "\n",
    "    df.loc[df.index.hour.isin([12,13,14,15,16,17,18,19,20]), 'us_session'] = 1\n",
    "    df.loc[df['us_session'] != 1, 'us_session'] = 0\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_change(df, periods):\n",
    "    #df['change'] = (df['close'].shift(-periods) - df['close'])\n",
    "    \n",
    "    mean_list = []\n",
    "    for i in range(periods):\n",
    "        mean_list.append((df['close'].shift(-1-i)+df['open'].shift(-1-i)+df['low'].shift(-1-i)+df['high'].shift(-1-i))/4 - df['close'])\n",
    "    \n",
    "    df['change'] = sum(mean_list)/len(mean_list)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df, plus_change, minus_change):\n",
    "    df.loc[df['change'] > plus_change,'label'] = 2\n",
    "    #df.loc[df['change'] < -minus_change,'label'] = 1\n",
    "    df.loc[df['label'].isna(),'label'] = 0\n",
    "    \n",
    "    df = df.drop(['open', 'change'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, periods):\n",
    "    # friday evening\n",
    "    df = df[~((df.index.dayofweek == 4) & (df.index.hour >= (20-periods)))]\n",
    "    # calendar\n",
    "    df = df[df['impact'] == 0 ]\n",
    "    # monday's morning\n",
    "    df = df[~((df.index.dayofweek == 0) &( df.index.hour < 7))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day_counter(df):\n",
    "    for i, date in enumerate(sorted(list(set(df.index.date)))):\n",
    "        df.loc[df.index.date == date ,'day_index'] = i\n",
    "        \n",
    "    df['weekday'] = df.index.dayofweek.values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data for all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity_param = 'M15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = cal(client, 'GBP_USD', 7776000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = hist(client, 'GBP_USD', 90, 0, granularity_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merge(history, calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged[merged.index.duplicated(keep=False) == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged[merged.index.duplicated(keep='first') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(merged.index.date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = 3\n",
    "days_to_train = 30\n",
    "plus_change = 0.0003\n",
    "minus_change = 0.0003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacek/anaconda3/lib/python3.7/site-packages/ta/trend.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (dip_mio[i]/trs[i])\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/ta/trend.py:174: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (din_mio[i]/trs[i])\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/ta/trend.py:634: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  aroon_up = close.rolling(n).apply(lambda x: float(np.argmax(x) + 1) / n * 100)\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/ta/trend.py:656: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "  aroon_down = close.rolling(n).apply(lambda x: float(np.argmin(x) + 1) / n * 100)\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:366: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(new_indexer, value)\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jacek/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "with_broaden_impact = broaden_impact(merged, periods)\n",
    "with_ta_impact = with_broaden_impact\n",
    "for i in range(periods):\n",
    "    with_ta_impact = add_ta(with_ta_impact, i+1)\n",
    "with_ta_impact_sessions = add_sessions(with_ta_impact)\n",
    "with_ta_impact_sessions_change = add_change(with_ta_impact_sessions, periods)\n",
    "labeled = label(with_ta_impact_sessions_change, plus_change, minus_change)\n",
    "final = labeled.dropna(axis=1, how='any')\n",
    "final = add_day_counter(final)\n",
    "final = filter_data(final, periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    3393\n",
       "2.0    1161\n",
       "Name: vol, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.groupby('label').count()['vol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the best parameters combination\n",
    "So for each parameters train model on past X days, check performance at next day\n",
    "save the scores for each day and summarize them at the end of a whole dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_criterions = ['entropy','gini']\n",
    "tree_max_depths = [6, 10, 14, 20, 30]\n",
    "tree_min_samples_leafs = [25, 35, 60, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "# test each kind of tree\n",
    "for criterion in tree_criterions:\n",
    "    for max_depth in tree_max_depths:\n",
    "        for min_samples_leaf in tree_min_samples_leafs:\n",
    "            \n",
    "            # on each date range\n",
    "            period_pred_Y = []\n",
    "            period_test_Y = []\n",
    "            for i in range(len(final['day_index'].unique()) - days_to_train):\n",
    "\n",
    "                train_df = final[(final['day_index'] >= i) & (final['day_index'] < (i+days_to_train))]\n",
    "                train_Y = train_df['label'].values.tolist()\n",
    "                train_X = train_df.drop(['close', 'high', 'low', 'vol', 'impact', 'label','day_index'], axis=1).values\n",
    "\n",
    "                test_df = final[final['day_index'] == (i + days_to_train)]\n",
    "                if not test_df.empty:\n",
    "                    test_Y = test_df['label'].values.tolist()\n",
    "                    test_X = test_df.drop(['close', 'high', 'low', 'vol', 'impact', 'label','day_index'], axis=1).values\n",
    "\n",
    "                    clf = ExtraTreesClassifier(n_estimators=30)\n",
    "                    clf = clf.fit(train_X, train_Y)\n",
    "\n",
    "                    # pick only those features (technical indicators) which hase at least mean influence on y label\n",
    "                    model = SelectFromModel(clf, prefit=True, threshold=\"mean\")\n",
    "\n",
    "                    train_X = train_X[:, model.get_support()]\n",
    "                    test_X = test_X[:, model.get_support()]\n",
    "\n",
    "        \n",
    "                    clf = tree.DecisionTreeClassifier(criterion=criterion,\n",
    "                                         max_depth=max_depth,\n",
    "                                         min_samples_leaf=min_samples_leaf)\n",
    "                    clf.fit(train_X, train_Y)\n",
    "                    pred_Y = clf.predict(test_X)\n",
    "                    \n",
    "                    # add predictions for each 'subperiod'\n",
    "                    for i in range(len(pred_Y)):\n",
    "                        period_pred_Y.append(pred_Y[i])\n",
    "                        period_test_Y.append(test_Y[i])\n",
    "\n",
    "        row = []\n",
    "        row.append(i)\n",
    "        row.append(criterion)\n",
    "        row.append(max_depth)\n",
    "        row.append(min_samples_leaf)\n",
    "        row.append(clf)\n",
    "        # dummy score for whole dataframe\n",
    "        good = 0\n",
    "        bad = 0\n",
    "        for i in range(len(period_pred_Y)):\n",
    "            if period_pred_Y[i] == period_test_Y[i] and period_pred_Y[i] != 0:\n",
    "                good = good + 1\n",
    "            if period_pred_Y[i] != period_test_Y[i] and period_pred_Y[i] != 0:\n",
    "                bad = bad + 1\n",
    "        \n",
    "        if good+bad != 0:\n",
    "            row.append(good/(good+bad))\n",
    "        else:\n",
    "            row.append(0)\n",
    "        counter = 0\n",
    "        for record in period_pred_Y:\n",
    "            if record != 0:\n",
    "                counter = counter + 1\n",
    "        row.append(counter)\n",
    "        row.append(period_pred_Y)\n",
    "        row.append(period_test_Y)\n",
    "        df_list.append(row)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(df_list, columns=['day_index','criterion','max_depth','min_samples_leaf','clf','score', 'count', 'pred_Y', 'test_Y'])\\\n",
    "    .sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here are the best classifiers, where \"the best\" means that it had just best direction prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_index</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>clf</th>\n",
       "      <th>score</th>\n",
       "      <th>count</th>\n",
       "      <th>pred_Y</th>\n",
       "      <th>test_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67</td>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>130</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.267606</td>\n",
       "      <td>142</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67</td>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>159</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day_index criterion  max_depth  min_samples_leaf  \\\n",
       "5         67      gini          6               100   \n",
       "1         67   entropy         10               100   \n",
       "8         67      gini         20               100   \n",
       "\n",
       "                                                 clf     score  count  \\\n",
       "5  DecisionTreeClassifier(class_weight=None, crit...  0.292308    130   \n",
       "1  DecisionTreeClassifier(class_weight=None, crit...  0.267606    142   \n",
       "8  DecisionTreeClassifier(class_weight=None, crit...  0.264151    159   \n",
       "\n",
       "                                              pred_Y  \\\n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              test_Y  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# many changes\n",
    "scores.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacek/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "df_list = []\n",
    "neural_network_layers = [\n",
    "    (10,10,5),\n",
    "    (20,30,10),\n",
    "    (15,20,5),\n",
    "    (5,10,2),\n",
    "    (20,2),\n",
    "    (10,2),\n",
    "    (10,30,15,2),\n",
    "    (40, 30, 2),\n",
    "    (60, 80, 40, 10, 2),\n",
    "]\n",
    "\n",
    "# test each kind of tree\n",
    "for layers in neural_network_layers:\n",
    "            \n",
    "    # on each date range\n",
    "    period_pred_Y = []\n",
    "    period_test_Y = []\n",
    "    for i in range(len(final['day_index'].unique()) - days_to_train):\n",
    "\n",
    "        train_df = final[(final['day_index'] >= i) & (final['day_index'] < (i+days_to_train))]\n",
    "        train_Y = train_df['label'].values.tolist()\n",
    "        train_X = train_df.drop(['close', 'high', 'low', 'vol', 'impact', 'label','day_index'], axis=1).values\n",
    "\n",
    "        test_df = final[final['day_index'] == (i + days_to_train)]\n",
    "        if not test_df.empty:\n",
    "            test_Y = test_df['label'].values.tolist()\n",
    "            test_X = test_df.drop(['close', 'high', 'low', 'vol', 'impact', 'label','day_index'], axis=1).values\n",
    "\n",
    "            clf = MLPClassifier(hidden_layer_sizes=layers,\n",
    "                               max_iter=300)\n",
    "            clf.fit(train_X, train_Y)\n",
    "            pred_Y = clf.predict(test_X)\n",
    "\n",
    "            # add predictions for each 'subperiod'\n",
    "            for i in range(len(pred_Y)):\n",
    "                period_pred_Y.append(pred_Y[i])\n",
    "                period_test_Y.append(test_Y[i])\n",
    "\n",
    "    row = []\n",
    "    row.append(i)\n",
    "    row.append(layers)\n",
    "    row.append(clf)\n",
    "    # dummy score for whole dataframe\n",
    "    good = 0\n",
    "    bad = 0\n",
    "    for i in range(len(period_pred_Y)):\n",
    "        if period_pred_Y[i] == period_test_Y[i] and period_pred_Y[i] != 0:\n",
    "            good = good + 1\n",
    "        if period_pred_Y[i] != period_test_Y[i] and period_pred_Y[i] != 0:\n",
    "            bad = bad + 1\n",
    "\n",
    "    if good+bad != 0:\n",
    "        row.append(good/(good+bad))\n",
    "    else:\n",
    "        row.append(0)\n",
    "    counter = 0\n",
    "    for record in period_pred_Y:\n",
    "        if record != 0:\n",
    "            counter = counter + 1\n",
    "    row.append(counter)\n",
    "    row.append(period_pred_Y)\n",
    "    row.append(period_test_Y)\n",
    "    df_list.append(row)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nn = pd.DataFrame(df_list, columns=['day_index','layers','clf','score', 'count', 'pred_Y', 'test_Y'])\\\n",
    "    .sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_index</th>\n",
       "      <th>layers</th>\n",
       "      <th>clf</th>\n",
       "      <th>score</th>\n",
       "      <th>count</th>\n",
       "      <th>pred_Y</th>\n",
       "      <th>test_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67</td>\n",
       "      <td>(60, 80, 40, 10, 2)</td>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>0.291139</td>\n",
       "      <td>395</td>\n",
       "      <td>[0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>(15, 20, 5)</td>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>0.288788</td>\n",
       "      <td>883</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>(20, 30, 10)</td>\n",
       "      <td>MLPClassifier(activation='relu', alpha=0.0001,...</td>\n",
       "      <td>0.279915</td>\n",
       "      <td>936</td>\n",
       "      <td>[0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day_index               layers  \\\n",
       "8         67  (60, 80, 40, 10, 2)   \n",
       "2         67          (15, 20, 5)   \n",
       "1         67         (20, 30, 10)   \n",
       "\n",
       "                                                 clf     score  count  \\\n",
       "8  MLPClassifier(activation='relu', alpha=0.0001,...  0.291139    395   \n",
       "2  MLPClassifier(activation='relu', alpha=0.0001,...  0.288788    883   \n",
       "1  MLPClassifier(activation='relu', alpha=0.0001,...  0.279915    936   \n",
       "\n",
       "                                              pred_Y  \\\n",
       "8  [0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, ...   \n",
       "\n",
       "                                              test_Y  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nn.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: add more features from the past (changes from t-k where k in {1...10}) and test NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
